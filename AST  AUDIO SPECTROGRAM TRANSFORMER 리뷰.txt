AST : AUDIO SPECTROGRAM TRANSFORMER 리뷰

오디오 분류 문제

1. AST p.2 2.2 절 <ImageNet Pretraining> 에는 Transformer 기반의 모델이 performance 향상을 위해 CNN 보다 더 많은 데이터를 필요로 한다고 나와 있습니다. 왜 그런가요? 

> One disadvantage of the Transformer compared with CNNs is
that the Transformer needs more data to train ….
> 

대답 - cnn은 convolution filter를 사용해서 지역적인 정보를 추출하기 쉽지만, 트랜스포머는 주어진 데이터의 상관관계를 추출해야 함. 따라서 데이터가 적다면 상관관계를 추측하기 어려움. 오디오 도메인은 앞뒤의 데이터가 서로 상관관계를 가지므로, 트랜스포머 모델이 더욱 적합하고, 이 모델에 사용될 데이터의 상관관계를 유추하기 위해 더 많은 데이터가 필요함

1. AST p.4 <Impact of Patch Split Overlap> 에서는 아래와 같은 표현이 있습니다. 아래 글에서 ‘quadratically’ 라는 표현에 대해 더 자세히 설명해 주세요.

> However, increasing the overlap also leads to longer patch sequence inputs
to the Transformer, which will quadratically increase the computational overhead.
> 

대답 - 16*16의 윈도우와 10의 hop_length를 가지는데, 이때 hop_length를 줄인다면, 2차원으로 겹치는 부분이 늘어나므로, 줄인 비율의 제곱만큼 윈도우의 갯수가 늘어나는 효과가 나타남

1. 어떠한 Pretraining도 하지 않은 AST에서 Classification token의 위치를 다르게 해 만들어 보겠습니다.  $E_{[CLS]}, E_{[1]} , ...E_{[8]}$ 의 순서인 기존 AST 모델을 $AST_{first}$, Classification token의 위치가 맨 뒤에 있는 형태의 모델(i.e. $E_{[2]}, E_{[2]} , ...E_{[CLS]}$)을 $AST_{last}$라고 하겠습니다. 두 모델을 충분히 학습했다고 가정했을 때 두 모델 $AST_{first}$ 와 $AST_{last}$의 성능은 달라질까요? 이유와 함께 설명해 주세요.

대답 - cls토큰을 사전에 선언하고 이후 데이터를 반영하던지, 이전의 데이터들을 모두 집약하고 최종적으로 cls토큰에 데이터를 반영하는 방식이므로 차이가 있을것 같지는 않음. 중요한 것은 연속된 데이터의 입력이 하나로 묶이는 것이고, 어느 시점에 데이터들을 추출하는 것인가 인 것 같음.

1. AST가 가지는 한계점을 한 가지 이상 적어 주세요. (Optional) 

대답 - 

비전 영역의 CNN(VIT)의 스펙트로그램의 적용

1. 분류 문제를 주었는데 뛰어남
    1. AUDIOSET, ESC-50 데이터셋
2. 구조 변경없이 다양한 길이의 데이터를 다룰 수 있음
    1. 1~10초간의 데이터 줌
    2. CNN기반 모델은 수정이 필요했음
3. SOTA CNN모델과 비교했을때, 더 작은 파라미터 갯수를 가짐, 심지어 더 빠름

처음으로 나온 순수한 어텐션 기반 오디오 분류 모델임

모델 구조

- 오디오 웨이브 폼
    - 128 dimension 멜 필터로 구성
    - 윈도우 크기 25ms, hop_length 10ms로 해서 각 샘플별 15ms씩 겹치게 구성
    - 결과는 128*100t의 스펙트로그램으로 구성됨
    - 16*16의 픽셀로 분할되고, 6픽셀씩 겹침(10픽셀씩 이동시킴)
    - 최종적으로 12(100t-16)/10 개의 패치로 분할됨
- 선형 변환을 통해 768 크기의 1차원 벡터로 변경시킴(임베딩 레이어와 동일역할)
- 위치 임베딩을 추가함
- 시작 지점에 cls 토큰 추가
- 모델은 인코더, 디코더 몇 개로 구성됨
    - 기존 인코더 그대로 사용함
        - 텐서플로우, 파이토치에서 셋업, 재생산이 쉬움
        - 기존 모델에서 전이학습이 쉬움
        - 시그모이드 함수를 통해 구분이 가능해짐

이미지 넷 사전 학습

- 트랜스포머 데이터셋은 cnn보다 데이터 셋이 많이 필요함
- 스펙트로그램이 이미 2차원(시간, 주파수)로 이루어진 이미지 형태를 가지게 되므로 이미지 데이터로 학습된 특징을 오디오에도 적용할 수 있음
    - imagenet, resnet등의 모델을 적용해 사전학습된 내용을 쉽게 쓸 수 있음
- VIT, AST는 비슷한 구조를 가짐
    - 일반적인 트랜스포머 모델
    - 동일 패치 사이즈
    - 동일한 임베딩 적용
        - 하지만 조금 다른점 존재

1. VIT는 3종류의 레이어(RGB) 사용, 하지만 AST는 1개의 레이어만 사용함
    1. 따라서 AST의 1개의 레이어를 3개로 확장시켜야 함
    2. 평균 0, 표준편차 0.5 가지게 정규화 시킴
2. VIT는 일반적으로 224*224 또는 384*384 크기로 입력크기가 고정됨
    1. 오디오는 길이가 달라질 수 있음
    2. 따라서 부분만 학습되지 않게 해야할 필요가 있음(보던데만 본다는 것 같음, 아니면 일정 크기만 확인한다던가)
    3. 포지셔널 임베딩의 적용을 위해서
        1. 자르거나(앞부분, 뒷부분만 쓰기?)
        2. 쌍선형 보간법(포지셔널 임베딩의 길이를 데이터 길이에 비례해서 확대)
    4. CLS 토큰을 통해 자르거나 변환된 위치 값들을 활용함
3. 마지막 CLASSIFICATION 레이어 버림

실험

- AUDIOSET 데이터셋
- 527종류의 라벨 달린 인터넷에서 가져온 데이터들
    - 균형 데이터셋 22k
    - 학습 데이터셋 2m
    - 평가 데이터셋 20k
- PLSA 모델과 동일한 파이프셋 활용
- 데이터 증강 비율 0.5
- 시간 192 프레임
- 주파수 48프레임
- 배치사이즈 12
- ADAM 최적화 함수
- 이진 분류 손실함수(BINARY CROSS ENTROPY LOSS)
- 학습률 5e-5
- epoch 25
- 초기 학습 5번은 1e-5로 5번 반복함
- 평가 기준은 mAP 사용함

ENSEMBLE-S

- 동일 세팅으로 3번 실험
- 랜덤 시드
    - 결과 0.475 정확도

ENSEMBLE-M

- 다른 세팅으로 실험
- 다른 패치로 분리해서 실험(패치 크기, 밸런스 데이터셋 비율 다르게 함)
    - 결과 0.485 정확도
- AST는 5번의 에폭을 사용했고, CNN기반 모델을 30번의 에폭을 사용함
- 데이터 셋이 작은 경우에도 해봄
- CNN기반 모델보다 더 좋은 성능을 보임

소거 학습(모델의 일부를 제거해서 경량화 또는 최적화)

- 이미지넷 사전학습의 영향
    - 사전 학습된 경우, 랜덤으로 지정된 경우
        - 데이터가 적은 경우, 사전 학습된 케이스가 우수함
- 포지셔널 임베딩의 적용 영향
    - 비율에 맞는 포지셔널 임베딩, 랜덤으로 지정된 포지셔널 임베딩
        - 적절한 포지셔널 임베딩보다 랜덤 지정된 포지셔널 임베딩의 성능이 크게 하락함
- 패치 분할 겹침 여부
    - 겹치는 부분의 증가 → 아주 큰 계산의 증가로 이어짐(제곱적으로 증가)
        - 패치가 한쪽 방향으로 늘어나는 것이 아닌, 2차원이라 한쪽 방향의 제곱만큼 계산 횟수의 증가가 일어남
- 패치 사이즈, 모양의 영향
    - 정사각형 모양(16*16)의 추출
    - 또다른 모양(128*2, 32*32)을 사용해봄
        - 일단 128*2의 형태가 좀 더 결과가 잘 나옴
        - 하지만 imagenet의 사전학습에 적용하기엔 적합하지 않았음
        - 작은 패치 사이즈가 좀 더 결과가 좋았음

ESC-50에 대한 결과

- 50 클래스, 2000개의 5초짜리 데이터
- SOTA-S(스크래치), SOTA-P(오디오셋 사전학습)
- AST-S(IMAGENET만 학습), AST-P(IMAGENET, 오디오셋 학습)
    - 배치사이즈 48
    - 아담 옵티마이저
    - 시작 학습률 1e-5에서 에폭 5번 이후부턴 0.85비율로 줄임
- 각 실험을 3번 반복해서 평균값을 구함